---
title: Setting up SLOs with Express
date: 2023-07-04
---

import { Callout, Cards, Card } from "nextra-theme-docs"

# Setting up SLOs with an Express

In this guide we'll go over what are Service Level Objectives (SLO), why you would want to adopt them for your alerting, and how you can accomplish that in your Express application.

## Why SLOs

Chances are - your uptime alerts aren't great.

They may be either firing too often, bothering you enough to mute that Slack channel, or they are too slow at notifying when they should have and you end up getting calls from your customer support.

If they're based on logs, they are likely relying on information that is delayed (e.g.: while your logs are ingesting) and may be unreliable (due to the changing nature of logs).

Finally, they are also probably hard to use to assess how affected your users actually are by the error. If my `service_proxy_02` is acting up - what does that *actually* mean for people using the website?

A better way to set up alerts is using the Service Level Objectives or SLOs. Popularized in the [Google SRE book](https://sre.google/workbook/implementing-slos/) - SLOs enable engineers to set up alerts for user-focused teams. SLO alerts align best with the user experience, e.g. response and error rates of a service, are actionable and can often give you a "gas leak" warning before the issue escalates.

So how do they work?

## How SLOs work

Here comes the ~science~ math bit:

SO how do they actually work? Well, there’s two key concepts that need to be understood in order to explain this, **error budgets** and **burn rates**.

An error budget is the amount of errors that your SLO allows for during normal operations. For example if you have an error SLO of 99% over a 28 day period, then what you’re saying is that the service is allowed to throw 1% of errors over that period of time. For every 100 requests the service receives, one request can generate an error and the service is still working exactly to its SLO. This number of allowed errors is your error budget, they’re budgeted into the SLO. Put in mathematical terms the error budget can be described as:

$\text{Error budget} = 1 - SLO$

So for an SLO of 99% the error budget is:

$1 - 0.99 = 0.01$

In practical terms this means that the error budget is one request in every hundred.

The burn rate takes this a bit further. The burn rate is the rate at which a service is burning through its error budget, where a burn rate of 1 would perfectly consume the error budget within the time window. For our previous example with an SLO of 99.9% over a 28 day period a burn rate of 1 would be consistently having one request generate an error in every thousand requests for that 28 day period. If the burn rate increases above this then the service is burning its error budget too fast and will likely consume it before the 28 days is up. For example, a burn rate of 2 would mean that the error budget is consumed within just 14 days!

The burn rate makes up the basis of the SLO-based alert.

One final note before we dive in: SLOs are part-science and part-art. Hopefully this guide gives you a confident place to start, but you will likely need to tweak the values that fit your precise business needs and processes. The best way to learn SLOs after all, like any concept in engineering, is to go build with them.

### How SLOs (and alerting) work in Autometrics

In the languages that we have Autometrics library for, you can create your SLOs directly in the same code as your application.

...
    

## Implementing SLOs in Express (using Autometrics)

Ok let's get to the real part of this guide.

<Callout type="info">

#### Pre-requisites

- **Autometrics library for TypeScript/JavaScript** installed: see [quickstart](/typescript/quickstart) for installation instructions.
- **Prometheus**. A powerful open source monitoring and alerting database that Autometrics is designed to interface with. You can get started with it locally quickly using the [Autometrics CLI](/local-development) or download the binary directly.

</Callout>

Let's take a toy example Express API that models a basic user directory. Currently it has a single endpoint /users where accepts requests to manage the user directory (create, update, delete users).

Our API code is split up into two modules (files):

- `server.ts` - our main entry point, we'll focus on this file mostly for the guide;

```typescript filename="server.ts"
import express, { Request, Response } from "express";
import { 
  handleCreateUser,
  handleDeleteUser,
  handleUpdateUser,
  handleGetAllUsers,
  handleGetUserById
} from "./routes.js"
  
const app = express();

app.get("/users", handleGetAllUsers);
app.get("/users/:id", handleGetUserById);
app.post("/users", handleCreateUser);
app.put("/users/:id", handleUpdateUser);
app.delete("/users/:id", handleDeleteUser);

app.listen(3000, () => {
  console.log("Server started on port 3000");
});

```

- `routes.ts`  - where all of our handlers are defined.
    
```typescript filename="routes.ts"
import { Request, Response } from "express";

export function handleGetAllUsers(req: Request, res: Response) {
  // ...
}

export function handleGetUserById(req: Request, res: Response) {
 // ...
}

export function handleCreateUser(req: Request, res: Response) {
  // ...
}

export function handleUpdateUser(req: Request, res: Response) {
  // ...
}

export function handleDeleteUser(req: Request, res: Response) {
  // ...
}
```
  

### Adding Autometrics to the project

The first thing we need to do is to make sure that we're generating the metrics necessary to create our SLOs. We can do that simply by wrapping our handlers in a `autometrics` higher order function.
  
```typescript filename="server.ts" {1,8-12}
import { autometrics } from "@autometrics/autometrics"
import express, { Request, Response } from "express";

//...

const app = express();

app.get("/users", autometrics(handleGetAllUsers));
app.get("/users/:id", autometrics(handleGetUserById));
app.post("/users", autometrics(handleCreateUser));
app.put("/users/:id", autometrics(handleUpdateUser));
app.delete("/users/:id", autometrics(handleDeleteUser));


```

You can use the same `autometrics` interface to continue wrapping other functions that are called inside your handlers, for example any functions that are calling out to the database or doing any other heavy business logic. 

It's quite simple: the more you add - the better a picture you will be able to build from your metrics data.

For each wrapped function, autometrics will create metrics that are necessary to assess basic availability questions like:
- Rate: how many requests has this function received?
- Error: how many of them errored?
- Duration: how long do the requests take?

These are the basic building blocks we'll use to build our Service Level Objectives.

### Creating an SLO

We can create our SLO right in the same place - the `@autometrics/autometrics` library includes helper utilities for that: `Objective`, `ObjectiveLatency`, `ObjectivePercentile`.

```typescript filename="server.ts"
import {
  autometrics,
  Objective,
  ObjectiveLatency,
  ObjectivePercentile,
} from "@autometrics/autometrics";
import express, { Request, Response } from "express";

// ...

```
  
All of these utilities are simply interfaces that you can use to create an object that we can then pass to each of our `autometrics` wrapped handlers. 

Here's how that works.

```typescript
const API_SLO: Objective = {
    name: "api",
    successRate: ObjectivePercentile.P99,
    latency: [ObjectiveLatency.Ms250, ObjectivePercentile.P99]
}
```

First, we create an `Objective` object that we're gonna call `API_SLO`. In this object we need to pass a descriptive `name`, and two parameters: `successRate` and `latency`. 

The `successRate` accepts the `ObjectivePercentile` enum value - for example `ObjectivePercentile.P99` for an objective of success rate of 99%. 

The `latency` accepts a tuple `[A, B]` which should include the latency goal in milliseconds and similarly a percentile. So: `[ObjectiveLatency.Ms250, ObjectivePercentile.P99]` translates that we _expect 99% of requests to be completed within 250 milliseconds_.

### Adding SLOs to our functions

For each function we want to group into our SLO, we simply pass in our newly created `API_SLO` as the `objective` property in the options parameter. In our toy example we will group all of our handlers - in real usage you can extend it to group any underlying important functions as well.

```typescript filename="server.ts" {14-18}
import { autometrics } from "@autometrics/autometrics"
import express, { Request, Response } from "express";

//...

const app = express();

const API_SLO: Objective = {
    name: "api",
    successRate: ObjectivePercentile.P99,
    latency: [ObjectiveLatency.Ms250, ObjectivePercentile.P99]
}

app.get("/users", autometrics({ objective: API_SLO }, handleGetAllUsers));
app.get("/users/:id", autometrics({ objective: API_SLO }, handleGetUserById));
app.post("/users", autometrics({ objective: API_SLO }, handleCreateUser));
app.put("/users/:id", autometrics({ objective: API_SLO }, handleUpdateUser));
app.delete("/users/:id", autometrics({ objective: API_SLO }, handleDeleteUser));
```

#### Setting custom error values

Autometrics by default registers an error when a given function throws an Error object. In top level functions like handlers we rarely want to throw the error back to user - it is a good practice to wrap any other function calls in the body of the function in a `try...catch` and return more informative errors to the user.

To make sure Autometrics register the error correctly, you can pass in a `recordErrorIf` callback to determine whether to register the result as an error based on the return value. 

For example in this case we want to register an error any time a route handler returns HTTP codes 4xx and 5xx. We can define the callback:

```typescript
const recordErrorIf = (res: express.Response) => {
  return res.statusCode >= 400 && res.statusCode <= 599;
};
```

And pass in this callback to the same `AutometricsOptions` object:

```typescript filename="server.ts"
const recordErrorIf = (res: express.Response) => {
  return res.statusCode >= 400 && res.statusCode <= 599;
};

app.get("/users", autometrics({ recordErrorIf, objective: API_SLO }, handleGetAllUsers));
app.get("/users/:id", autometrics({ recordErrorIf, objective: API_SLO }, handleGetUserById));
app.post("/users", autometrics({ recordErrorIf, objective: API_SLO }, handleCreateUser));
app.put("/users/:id", autometrics({ recordErrorIf, objective: API_SLO }, handleUpdateUser));
app.delete("/users/:id", autometrics({ recordErrorIf, objective: API_SLO }, handleDeleteUser));
```

### Viewing the SLOs

That's all for the instrumentation part!

Autometrics will now emit metrics with special labels that Prometheus can group into. You can check out more how this works under the hood in [this blogpost](https://fiberplane.com/blog/an-adventure-with-slos-generic-prometheus-alerting-rules-and-complex-promql-queries).

You can preview and validate the SLOs using the Autometrics CLI and Explorer. Navigate to the "SLO" tab in the top left to see an overview list of the SLOs you've just created (our example should have a single item named "api").

If you're using Grafana you can load one of the pre-made [Autometrics dashboards](https://grafana.com/grafana/dashboards/18506-autometrics-service-level-objectives-slos/). You don't need to configure the dashboard - it will automatically pick up all Autometrics-generated data from your Prometheus and show a helpful SLO overview panel with the current score on the left side and the functions that comprise that SLO on your right:

//IMAGE//

### Configuring Alerts

Finally, you can configure alerts for this setup.

Grab the Autometrics alerting rule-set. No need to configure anything - the alerts will be dormant by default and activate only when they find SLO labels on Autometrics-instrumented data.

<Cards num={2}>
	<Card
	children
	icon
	title="Autometrics alerting rules"
    arrow
	href="https://github.com/autometrics-dev/autometrics-shared/blob/main/autometrics.rules.yml"
	/>
</Cards>

Load the file into Prometheus Alertmanager:

### Recap

And we're set!

We started off with a simple Express application and in a few steps instrumented our service to report the basic metrics required to assess its health: rate, errors, and duration. On top of that we've grouped them into a Service Level Objective (SLO) to help us give a more structured insight into a question: is our service running smoothly for the users. This enabled us to add smarter alerts based on that data.

A few things to note:
- as mentioned earlier, SLOs are an art as much as science: a week after deploying this you will probably need to tweak them to your needs. The good news is that the only thing you need to change is the `API_SLO` object we've created at the beginning.
