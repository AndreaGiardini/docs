---
title: Setting up SLOs with Express
date: 2023-07-04
---

import { Callout, Cards, Card } from "nextra-theme-docs"

# Setting up SLOs with an Express

In this guide we'll go over what are Service Level Objectives (SLO), why you would want to adopt them for your alerting, and how you can accomplish that in your Express application.

## Why SLOs

SLOs enable engineers to set up alerts for user-focused teams. SLO alerts align best with the user experience, e.g. response and error rates of a service, are actionable and can often give you a "gas leak" warning before the issue escalates.

## How SLOs work

SLOs work on two principal ideas **error budgets** and **burn rates**. 

An **error budget** represents the allowable amount of errors or service disruptions that a service can experience within a given period without violating its agreed-upon reliability target. It can be represented as: $\text{Error budget} = 100\% - SLO$

So for an SLO of 99% the error budget is:

$100\% - 99\% = 1\%$

The **burn rate** is the rate at which the error budget is being consumed or “burned” by incidents or errors that occur in a system or service. A burn rate of 1 or lower indicates that the service is currently burning its error budget at a rate that is within SLO targets. A burn rate higher than 1 indicates that the service is burning its error budget too quickly, and would result in a failed SLO if not addressed.

The burn rate makes up the basis of the SLO-based alert.

One final note before we dive in: SLOs are part-science and part-art. Hopefully this guide gives you a confident place to start, but you will likely need to tweak the values that fit your precise business needs and processes. The best way to learn SLOs after all, like any concept in engineering, is to go build with them.

## Implementing SLOs in Express (using Autometrics)

Ok let's get to the real part of this guide.

<Callout type="info">

#### Pre-requisites

- **Autometrics library for TypeScript/JavaScript** installed: see [quickstart](/typescript/quickstart) for installation instructions.
- **Prometheus**. A powerful open source monitoring and alerting database that Autometrics is designed to interface with. You can get started with it locally quickly using the [Autometrics CLI](/local-development) or download the binary directly.

</Callout>

We will take a toy example Express API that models a basic user directory and add SLO-based alerts to it. Currently it has a single endpoint `/users` where it accepts requests to manage the user directory (create, update, delete users).

Our API code is split up into two modules (files):

- `server.ts` - our main entry point, we'll focus on this file mostly for the guide;

```typescript filename="server.ts"
import express, { Request, Response } from "express";
import { 
  handleCreateUser,
  handleDeleteUser,
  handleUpdateUser,
  handleGetAllUsers,
  handleGetUserById
} from "./routes.js"
  
const app = express();

app.get("/users", handleGetAllUsers);
app.get("/users/:id", handleGetUserById);
app.post("/users", handleCreateUser);
app.put("/users/:id", handleUpdateUser);
app.delete("/users/:id", handleDeleteUser);

app.listen(3000, () => {
  console.log("Server started on port 3000");
});

```

- `routes.ts`  - where all of our handlers are defined.
    
```typescript filename="routes.ts"
import { Request, Response } from "express";

export function handleGetAllUsers(req: Request, res: Response) {
  // ...
}

export function handleGetUserById(req: Request, res: Response) {
 // ...
}

export function handleCreateUser(req: Request, res: Response) {
  // ...
}

export function handleUpdateUser(req: Request, res: Response) {
  // ...
}

export function handleDeleteUser(req: Request, res: Response) {
  // ...
}
```
  

### Adding Autometrics to the project

The first thing we need to do is to make sure that we're generating the metrics necessary to create our SLOs. We can do that simply by wrapping our handlers in a `autometrics` higher order function.
  
```typescript filename="server.ts" {1,8-12}
import { autometrics } from "@autometrics/autometrics"
import express, { Request, Response } from "express";

//...

const app = express();

app.get("/users", autometrics(handleGetAllUsers));
app.get("/users/:id", autometrics(handleGetUserById));
app.post("/users", autometrics(handleCreateUser));
app.put("/users/:id", autometrics(handleUpdateUser));
app.delete("/users/:id", autometrics(handleDeleteUser));


```

You can use the same `autometrics` interface to continue wrapping other functions that are called inside your handlers, for example any functions that are calling out to the database or doing any other heavy business logic. 

It's quite simple: the more you add - the better a picture you will be able to build from your metrics data.

For each wrapped function, autometrics will create metrics that are necessary to assess basic availability questions like:
- Rate: how many requests has this function received?
- Error: how many of them errored?
- Duration: how long do the requests take?

These are the basic building blocks we'll use to build our Service Level Objectives.

### Creating an SLO

We can create our SLO right in the same place - the `@autometrics/autometrics` library includes helper utilities for that: `Objective`, `ObjectiveLatency`, `ObjectivePercentile`.

```typescript filename="server.ts"
import {
  autometrics,
  Objective,
  ObjectiveLatency,
  ObjectivePercentile,
} from "@autometrics/autometrics";
import express, { Request, Response } from "express";

// ...

```
  
All of these utilities are simply interfaces that you can use to create an object that we can then pass to each of our `autometrics` wrapped handlers. 

Here's how that works.

```typescript
const API_SLO: Objective = {
    name: "api",
    successRate: ObjectivePercentile.P99,
    latency: [ObjectiveLatency.Ms250, ObjectivePercentile.P99]
}
```

First, we create an `Objective` object that we're gonna call `API_SLO`. In this object we need to pass a descriptive `name`, and two parameters: `successRate` and `latency`. 

The `successRate` accepts the `ObjectivePercentile` enum value - for example `ObjectivePercentile.P99` for an objective of success rate of 99%. 

The `latency` accepts a tuple `[A, B]` which should include the latency goal in milliseconds and similarly a percentile. So: `[ObjectiveLatency.Ms250, ObjectivePercentile.P99]` translates that we _expect 99% of requests to be completed within 250 milliseconds_.

### Adding SLOs to our functions

For each function we want to group into our SLO, we simply pass in our newly created `API_SLO` as the `objective` property in the options parameter. In our toy example we will group all of our handlers - in real usage you can extend it to group any underlying important functions as well.

```typescript filename="server.ts" {14-18}
import { autometrics } from "@autometrics/autometrics"
import express, { Request, Response } from "express";

//...

const app = express();

const API_SLO: Objective = {
    name: "api",
    successRate: ObjectivePercentile.P99,
    latency: [ObjectiveLatency.Ms250, ObjectivePercentile.P99]
}

app.get("/users", autometrics({ objective: API_SLO }, handleGetAllUsers));
app.get("/users/:id", autometrics({ objective: API_SLO }, handleGetUserById));
app.post("/users", autometrics({ objective: API_SLO }, handleCreateUser));
app.put("/users/:id", autometrics({ objective: API_SLO }, handleUpdateUser));
app.delete("/users/:id", autometrics({ objective: API_SLO }, handleDeleteUser));
```

#### Setting custom error values

Autometrics by default registers an error when a given function throws an Error object. In top level functions like handlers we rarely want to throw the error back to user - it is a good practice to wrap any other function calls in the body of the function in a `try...catch` and return more informative errors to the user.

To make sure Autometrics register the error correctly, you can pass in a `recordErrorIf` callback to determine whether to register the result as an error based on the return value. 

For example in this case we want to register an error any time a route handler returns HTTP codes 4xx and 5xx. We can define the callback:

```typescript
const recordErrorIf = (res: express.Response) => {
  return res.statusCode >= 400 && res.statusCode <= 599;
};
```

And pass in this callback to the same `AutometricsOptions` object:

```typescript filename="server.ts"
const recordErrorIf = (res: express.Response) => {
  return res.statusCode >= 400 && res.statusCode <= 599;
};

app.get("/users", autometrics({ recordErrorIf, objective: API_SLO }, handleGetAllUsers));
app.get("/users/:id", autometrics({ recordErrorIf, objective: API_SLO }, handleGetUserById));
app.post("/users", autometrics({ recordErrorIf, objective: API_SLO }, handleCreateUser));
app.put("/users/:id", autometrics({ recordErrorIf, objective: API_SLO }, handleUpdateUser));
app.delete("/users/:id", autometrics({ recordErrorIf, objective: API_SLO }, handleDeleteUser));
```

### Viewing the SLOs

That's all for the code-writing part!

Autometrics will now emit metrics with special labels that Prometheus can group into. You can check out more how this works under the hood in [this blogpost](https://fiberplane.com/blog/an-adventure-with-slos-generic-prometheus-alerting-rules-and-complex-promql-queries).

You can preview and validate the SLOs using the Autometrics CLI and Explorer. Navigate to the "SLO" tab in the top left to see an overview list of the SLOs you've just created (our example should have a single item named "api").

![You can preview your SLOs in the Autometrics Explorer](/images/express_slo_preview.png)

If you're using Grafana you can load one of the pre-made [Autometrics dashboards](https://grafana.com/grafana/dashboards/18506-autometrics-service-level-objectives-slos/). You don't need to configure the dashboard - it will automatically pick up all Autometrics-generated data from your Prometheus and show a helpful SLO overview panel with the current score on the left side and the functions that comprise that SLO on your right.

### Configuring Alerts

Finally, based on this you can set up alerts inside Prometheus.

Grab the Autometrics alerting rule-set and append it to your Prometheus configuration. 

<Cards num={2}>
    <Card
    children
    icon
    title="Autometrics alerting rules"
    arrow
    href="https://github.com/autometrics-dev/autometrics-shared/blob/main/autometrics.rules.yml"
    />
</Cards>

No need to configure anything else - the alerts will be dormant by default and activate _only_ when they find SLO labels on Autometrics-instrumented data.

You can validate that the alerts are set by navigating to the "Alerts" tab in Prometheus UI.

### Recap

And we're set!

We started off with a simple Express application and in a few steps instrumented our service to report the basic metrics required to assess its health: rate, errors, and duration. On top of that we've grouped them into a Service Level Objective (SLO) to help us give a more structured insight into a question: is our service running smoothly for the users. This enabled us to add smarter alerts based on that data.

A few things to note:
- as mentioned earlier, SLOs are an art as much as science: a week after deploying this you will probably need to tweak them to your needs. The good news is that the only thing you need to change is the `API_SLO` object we've created at the beginning.
